md1_threat <- lmer(dwell_time ~ c_time * z_threat + (1 +  c_time * z_threat |id) + (1 +  c_time * z_threat|target), data=s1)
s1 <- s1 %>%
filter(Area == 'HEAD') %>%
mutate(c_time = scale(Time, center=1, scale=FALSE)) %>%
group_by(id) %>%
mutate(across(c('Masc', 'Threat', 'Attract'), scale, .names='Z_{col}')) %>%
ungroup() %>%
rename_all(tolower)
# Fit models
md1_threat <- lmer(dwell_time ~ c_time * z_threat + (1 +  c_time * z_threat |id) + (1 +  c_time * z_threat|target), data=s1)
md1_masc <- lmer(dwell_time ~ c_time * z_masc + (1|id) + (1|target), data=s1)
md1_attr <- lmer(dwell_time ~ c_time * z_attract + (1|id) + (1|target), data=s1)
# Get a summary printout of each model
lapply(setNames(list(md1_threat, md1_masc, md1_attr), c('Threat', 'Masculinity', 'Attractiveness')),
function(x) round(summary(x)$coefficients, 3))
# Fit models
md1_threat <- lmer(dwell_time ~ c_time * z_threat + (1|id) + (1|target), data=s1)
md1_masc <- lmer(dwell_time ~ c_time * z_masc + (1|id) + (1|target), data=s1)
md1_attr <- lmer(dwell_time ~ c_time * z_attract + (1|id) + (1|target), data=s1)
# Get a summary printout of each model
lapply(setNames(list(md1_threat, md1_masc, md1_attr), c('Threat', 'Masculinity', 'Attractiveness')),
function(x) round(summary(x)$coefficients, 3))
s1$dwell_time
predict(md1_masc)
hist(predict(md1_masc))
gr <- ref_grid(md1_threat, list=(c_time=0, z_threat=c(-2, 0, -2)))
gr <- ref_grid(md1_threat, list=c(c_time=0, z_threat=c(-2, 0, -2)))
emmeans(gr)
emmeans(gr, ~ c_time * z_threat)
emmeans(gr, ~ z_threat)
emmeans(gr, ~ z_threat | c_time)
gr <- ref_grid(md1_threat, list=c(c_time=c(0, 1, 2, 3), z_threat=c(-2, 0, -2)))
emmeans(gr, ~ z_threat | c_time)
emmeans(gr, ~ z_threat * c_time)
emmeans(gr, ~ z_threat | c_time)
gr <- ref_grid(md1_threat, list=c(c_time=c(0, 1, 2, 3), z_threat=c(-2, 0, 2)))
emmeans(gr, ~ z_threat | c_time)
emmeans(gr, ~ z_threat * c_time)
emmeans(gr, ~ z_threat)
emmeans(gr, ~ z_threat, 'pairwise')
emmeans(gr, ~ z_threat, by='pairwise')
contrast(gr)
contrast(gr, ~ z_threat)
contrast(gr, ~z_threat)
contrast(gr, ~z_threat|c_time)
contrast(gr, ~z_threat|c_time, 'pairwise')
contrast(gr, emmeans(gr, ~z_threat | c_time))
contrast(gr, emmeans(md1_threat, ~z_threat | c_time))
contrast(emmeans(md1_threat, ~z_threat | c_time))
?contrast
contrast(emmeans(md1_threat, ~z_threat | c_time), by=gr)
contrast(emmeans(md1_threat, ~ z_threat|c_time), by=gr)
contrast(emmeans(md1_threat, ~ z_threat|c_time))
contrast(emmeans(md1_threat, ~ z_threat|c_time), by=gr)
gr <- ref_grid(md1_threat, at=list(c_time=c(0, 1, 2, 3), z_threat=c(-2, 0, 2)))
gr
contrast(emmeans(md1_threat, ~ z_threat|c_time), by=gr)
contrast(emmeans(md1_threat, ~ z_threat|c_time))
contrast(emmeans(md1_threat, ~ z_threat, at=list(z_threat = c(-2, 0, 2), c_time=0)))
contrast(emmeans(md1_threat, ~ z_threat, at=list(z_threat = c(-2, 0, 2), c_time=c(0, 1, 2)))
)
contrast(emmeans(md1_threat, ~ z_threat|c_time, at=list(z_threat = c(-2, 0, 2), c_time=c(0, 1, 2)))
)
contrast(emmeans(md1_threat, ~ z_threat*c_time, at=list(z_threat = c(-2, 0, 2), c_time=c(0, 1, 2)))
)
contrast(emmeans(md1_threat, ~ z_threat|c_time, at=list(z_threat = c(-2, 0, 2), c_time=c(0, 1, 2)))
)
knitr::opts_chunk$set(echo=TRUE, message=FALSE, warning=TRUE)
library(bayesplot)
library(brms)
library(dplyr)
library(emmeans)
library(flextable)
library(ggplot2)
library(HDInterval)
library(lmerTest)
library(patchwork)
library(parallel)
library(readr)
library(tidyr)
library(stringr)
personal_theme = theme(plot.title = element_text(hjust = 0.5))
p <- 0.75
# Read in 'Eyetracking.csv'
data <- read.csv('Eyetracking.csv')
head(data)
# Split
s1 <- filter(data, Study == 1)
s2 <- filter(data, Study == 2)
rm(data) # Throw out the full dataset
comp_graph <- s1 %>%
group_by(Target, Area) %>%
summarise(mean_dwell = mean(Dwell_Time, na.rm=TRUE)) %>%
mutate(Area = str_to_title(Area)) %>%
ggplot(aes(x=factor(Target), y=mean_dwell, fill=factor(Area, levels=c('Head', 'Trunk', 'Legs')))) +
geom_bar(stat='identity', position='fill') +
labs(y='Average Dwell Time - Proportion', x='Target ID', fill='Area') +
theme_classic() +
scale_fill_grey(start=0.4, end=0.8) +
geom_hline(yintercept = 0.50)
ggsave('Figure1.png', comp_graph, width=7, height=4)
comp_graph
s1 <- s1 %>%
filter(Area == 'HEAD') %>%
mutate(c_time = scale(Time, center=1, scale=FALSE)) %>%
group_by(id) %>%
mutate(across(c('Masc', 'Threat', 'Attract'), scale, .names='Z_{col}')) %>%
ungroup() %>%
rename_all(tolower)
# Fit models
md1_threat <- lmer(dwell_time ~ c_time * z_threat + (1|id) + (1|target), data=s1)
md1_masc <- lmer(dwell_time ~ c_time * z_masc + (1|id) + (1|target), data=s1)
md1_attr <- lmer(dwell_time ~ c_time * z_attract + (1|id) + (1|target), data=s1)
# Get a summary printout of each model
lapply(setNames(list(md1_threat, md1_masc, md1_attr), c('Threat', 'Masculinity', 'Attractiveness')),
function(x) round(summary(x)$coefficients, 3))
## Explore these interactions through estimated marginal means
# Set up some points to evaluate at - the perceptual trait is ±2SDs, and we will do one for each second.
time <- 0:9
percept <- c(-2, 2)
# Lists to be passed to emmeans
eval_threat <- list(c_time = time, z_threat = percept)
eval_masc <- list(c_time = time, z_masc = percept)
eval_attract <- list(c_time = time, z_attract = percept)
# Estimate the marginal means at given levels for each model
threat_em <- emmeans(md1_threat, specs = ~ c_time|z_threat, at = eval_threat)
masc_em <- emmeans(md1_masc, specs = ~ z_masc|c_time, at = eval_masc)
attract_em <- emmeans(md1_attr, specs = ~ z_attract|c_time, at = eval_attract)
# The contrasts can then be printed out
lapply(list(threat_em, masc_em, attract_em), function(x) contrast(x, by='c_time'))
# Generate contrast datasets - there are a few steps here
# For every marginal mean collection:
# get the contrasts between each ±2D sd percept for every time level
# get the confindence intervals for this difference
# turn into a dataframe
# Set the names of the resulting list
# bind the rows together and preserve those names in a column
# filter out '2 effect' as this represents +2 SD - the effect of -2 SD.
# and get the confidence intervals, then make into a dataframe, and merge into a list, then set names
contrast_data <- lapply(list(threat_em, masc_em, attract_em),
function(x) as.data.frame(confint(contrast(x, by='c_time')))) %>%
setNames(c('Threat', 'Masculinity', 'Attractiveness')) %>%
bind_rows(.id='percept') %>%
filter(contrast == '2 effect')
# This can now be visualised
diff_plot <- ggplot(contrast_data, aes(x=c_time, y=estimate, shape=percept)) +
geom_line(aes(linetype=percept), position = position_dodge(p), alpha=.5) +
geom_point(size=2, position = position_dodge(p)) +
geom_errorbar(aes(ymin = asymp.LCL, ymax=asymp.UCL), width=0, position = position_dodge(p), alpha=.5) +
geom_hline(yintercept=0, alpha=.7) +
scale_x_continuous(labels=1:10, breaks=0:9) +
scale_y_continuous(limits=c(-17, 17), breaks=seq(-16, 16, 4)) +
labs(x = 'Time', y = 'Difference between predicted dwell time at\n±2SD of trait perception',
shape='Rating', linetype='Rating') +
theme_classic() +
personal_theme
ggsave('Figure2.png', diff_plot, width = 7 , height = 4)
diff_plot
s2 <- s2 %>%
filter(Area == 'HEAD') %>%
mutate(c_time = scale(Time, center=1, scale=FALSE)) %>%
group_by(id) %>%
mutate(across(c('Masc', 'Threat', 'Attract'), scale, .names='Z_{col}')) %>%
ungroup() %>%
rename_all(tolower)
# Fit models
md2_threat <- lmer(dwell_time ~ c_time * z_threat + (1|id) + (1|target), data=s2)
md2_masc <- lmer(dwell_time ~ c_time * z_masc + (1|id) + (1|target), data=s2)
md2_attr <- lmer(dwell_time ~ c_time * z_attract + (1|id) + (1|target), data=s2)
# Get a summary printout of each model
lapply(setNames(list(md2_threat, md2_masc, md2_attr), c('Threat', 'Masculinity', 'Attractiveness')),
function(x) round(summary(x)$coefficients, 3))
# Filter
female_only <- filter(s2, target_sex == "Female")
md2_threat_fonly <- lmer(dwell_time ~ c_time * z_threat + (1|id) + (1|target), data=female_only)
md2_masc_fonly <- lmer(dwell_time ~ c_time * z_masc + (1|id) + (1|target), data=female_only)
md2_attr_fonly <- lmer(dwell_time ~ c_time * z_attract + (1|id) + (1|target), data=female_only)
# Get a summary printout of each model
lapply(setNames(list(md2_threat_fonly, md2_masc_fonly, md2_attr_fonly), c('Threat', 'Masculinity', 'Attractiveness')),
function(x) round(summary(x)$coefficients, 2))
# Refit the three models for Study 2, using all data, with brms. Priors are kept at default, which is weakly informative (just stops very extreme estimates)
cores = detectCores() # Get the number of cores machine has
md2_threat_b <- brm(dwell_time ~ c_time * z_threat + (1|id) + (1|target), data=s2, chains=cores, cores=cores)
md2_masc_b <- brm(dwell_time ~ c_time * z_masc + (1|id) + (1|target), data=s2, chains=cores, cores=cores)
md2_attr_b <- brm(dwell_time ~ c_time * z_attract + (1|id) + (1|target), data=s2, chains=cores, cores=cores)
comp_graph <- s1 %>%
group_by(Target, Area) %>%
summarise(mean_dwell = mean(Dwell_Time, na.rm=TRUE)) %>%
mutate(Area = str_to_title(Area)) %>%
ggplot(aes(x=factor(Target), y=mean_dwell, fill=factor(Area, levels=c('Head', 'Trunk', 'Legs')))) +
geom_bar(stat='identity', position='fill') +
labs(x='Average Dwell Time - Proportion', y='Target ID', fill='Area') +
theme_classic() +
scale_fill_grey(start=0.4, end=0.8) +
geom_vline(xintercept = 0.50)
knitr::opts_chunk$set(echo=TRUE, message=FALSE, warning=TRUE)
library(bayesplot)
library(brms)
library(dplyr)
library(emmeans)
library(flextable)
library(ggplot2)
library(HDInterval)
library(lmerTest)
library(patchwork)
library(parallel)
library(readr)
library(tidyr)
library(stringr)
personal_theme = theme(plot.title = element_text(hjust = 0.5))
p <- 0.75
# Read in 'Eyetracking.csv'
data <- read.csv('Eyetracking.csv')
head(data)
# Split
s1 <- filter(data, Study == 1)
s2 <- filter(data, Study == 2)
rm(data) # Throw out the full dataset
comp_graph <- s1 %>%
group_by(Target, Area) %>%
summarise(mean_dwell = mean(Dwell_Time, na.rm=TRUE)) %>%
mutate(Area = str_to_title(Area)) %>%
ggplot(aes(x=factor(Target), y=mean_dwell, fill=factor(Area, levels=c('Head', 'Trunk', 'Legs')))) +
geom_bar(stat='identity', position='fill') +
labs(x='Average Dwell Time - Proportion', y='Target ID', fill='Area') +
theme_classic() +
scale_fill_grey(start=0.4, end=0.8) +
geom_vline(xintercept = 0.50)
ggsave('Figure1.png', comp_graph, width=7, height=4)
comp_graph
comp_graph <- s1 %>%
group_by(Target, Area) %>%
summarise(mean_dwell = mean(Dwell_Time, na.rm=TRUE)) %>%
mutate(Area = str_to_title(Area)) %>%
ggplot(aes(x=factor(Target), y=mean_dwell, fill=factor(Area, levels=c('Head', 'Trunk', 'Legs')))) +
geom_bar(stat='identity', position='fill') +
labs(x='Average Dwell Time - Proportion', y='Target ID', fill='Area') +
theme_classic() +
scale_fill_grey(start=0.4, end=0.8) +
geom_vline(yintercept = 0.50)
ggsave('Figure1.png', comp_graph, width=7, height=4)
comp_graph <- s1 %>%
group_by(Target, Area) %>%
summarise(mean_dwell = mean(Dwell_Time, na.rm=TRUE)) %>%
mutate(Area = str_to_title(Area)) %>%
ggplot(aes(x=factor(Target), y=mean_dwell, fill=factor(Area, levels=c('Head', 'Trunk', 'Legs')))) +
geom_bar(stat='identity', position='fill') +
labs(x='Average Dwell Time - Proportion', y='Target ID', fill='Area') +
theme_classic() +
scale_fill_grey(start=0.4, end=0.8) +
geom_vline(xintercept = 0.50)
ggsave('Figure1.png', comp_graph, width=7, height=4)
comp_graph
comp_graph <- s1 %>%
group_by(Target, Area) %>%
summarise(mean_dwell = mean(Dwell_Time, na.rm=TRUE)) %>%
mutate(Area = str_to_title(Area)) %>%
ggplot(aes(x=factor(Target), y=mean_dwell, fill=factor(Area, levels=c('Head', 'Trunk', 'Legs')))) +
geom_bar(stat='identity', position='fill') +
labs(x='Average Dwell Time - Proportion', y='Target ID', fill='Area') +
theme_classic() +
scale_fill_grey(start=0.4, end=0.8) +
geom_hline(yintercept = 0.50)
ggsave('Figure1.png', comp_graph, width=7, height=4)
comp_graph
comp_graph <- s1 %>%
group_by(Target, Area) %>%
summarise(mean_dwell = mean(Dwell_Time, na.rm=TRUE)) %>%
mutate(Area = str_to_title(Area)) %>%
ggplot(aes(y=factor(Target), x=mean_dwell, fill=factor(Area, levels=c('Head', 'Trunk', 'Legs')))) +
geom_bar(stat='identity', position='fill') +
labs(x='Average Dwell Time - Proportion', y='Target ID', fill='Area') +
theme_classic() +
scale_fill_grey(start=0.4, end=0.8) +
geom_hline(yintercept = 0.50)
ggsave('Figure1.png', comp_graph, width=7, height=4)
comp_graph
comp_graph <- s1 %>%
group_by(Target, Area) %>%
summarise(mean_dwell = mean(Dwell_Time, na.rm=TRUE)) %>%
mutate(Area = str_to_title(Area)) %>%
ggplot(aes(y=factor(Target), x=mean_dwell, fill=factor(Area, levels=c('Head', 'Trunk', 'Legs')))) +
geom_bar(stat='identity', position='fill') +
labs(x='Average Dwell Time - Proportion', y='Target ID', fill='Area') +
theme_classic() +
scale_fill_grey(start=0.4, end=0.8) +
geom_vline(xintercept = 0.50)
ggsave('Figure1.png', comp_graph, width=7, height=4)
comp_graph
knitr::opts_chunk$set(echo=TRUE, message=FALSE, warning=TRUE)
comp_graph <- s1 %>%
mutate(time_f = factor(Time, levels=1:10)) %>%
group_by(time_f, Area) %>%
summarise(mean_dwell = mean(Dwell_Time, na.rm=TRUE)) %>%
mutate(Area = str_to_title(Area)) %>%
ggplot(aes(y=mean_dwell, x=time_f, fill=factor(Area, levels=c('Head', 'Trunk', 'Legs')))) +
geom_bar(stat='identity', position='fill') +
labs(x='Time (seconds)', y='Average Dwell Time - Proportion', fill='Area') +
theme_classic() +
scale_fill_grey(start=0.4, end=0.8) +
geom_hline(yintercept = 0.50)
knitr::opts_chunk$set(echo=TRUE, message=FALSE, warning=TRUE)
library(bayesplot)
library(brms)
library(dplyr)
library(emmeans)
library(flextable)
library(ggplot2)
library(HDInterval)
library(lmerTest)
library(patchwork)
library(parallel)
library(readr)
library(tidyr)
library(stringr)
personal_theme = theme(plot.title = element_text(hjust = 0.5))
p <- 0.75
# Read in 'Eyetracking.csv'
data <- read.csv('Eyetracking.csv')
head(data)
# Split
s1 <- filter(data, Study == 1)
s2 <- filter(data, Study == 2)
rm(data) # Throw out the full dataset
comp_graph <- s1 %>%
mutate(time_f = factor(Time, levels=1:10)) %>%
group_by(time_f, Area) %>%
summarise(mean_dwell = mean(Dwell_Time, na.rm=TRUE)) %>%
mutate(Area = str_to_title(Area)) %>%
ggplot(aes(y=mean_dwell, x=time_f, fill=factor(Area, levels=c('Head', 'Trunk', 'Legs')))) +
geom_bar(stat='identity', position='fill') +
labs(x='Time (seconds)', y='Average Dwell Time - Proportion', fill='Area') +
theme_classic() +
scale_fill_grey(start=0.4, end=0.8) +
geom_hline(yintercept = 0.50)
ggsave('Figure1.png', comp_graph, width=7, height=4)
comp_graph
library(bayestestR)
sleep
View(sleep)
write.csv(sleep, file='sleep.csv', row.names = FALSE)
library(bayestestR)
library(rstanarm)
set.seed(123)
library(rstanarm)
model <- stan_glm(
formula = extra ~ group,
data = sleep,
prior = normal(0, 3, autoscale = FALSE),
chains = 10, iter = 5000, warmup = 1000
)
My_first_BF <- bayesfactor_parameters(model, null = c(-1, 1))
My_first_BF
install.packages("palmerpenguins")
library(palmerpenguins)
?`palmerpenguins-package`
data(package = 'palmerpenguins')
penguins
library(tidyverse)
write_csv(penguins, 'penguins.csv')
slice_sample(penguins, prop=.75)
write_csv(slice_sample(penguins, prop=.75), 'penguins_data.csv')
---
title: "RMarkdown Example"
author: "Alex Jones"
date: "27/05/2022"
output: html_document
---
```{r}
library(tidyverse) # Loads up the packages
# Read in the csv of our penguin data
penguins <- read_csv('https://osf.io/qhkma/download')
```
# Read in the csv of our penguin data
penguins <- read_csv('https://osf.io/qhkma/download')
library(tidyverse) # Loads up the packages
# Read in the csv of our penguin data
penguins <- read_csv('https://osf.io/qhkma/download')
head(penguins, 5)
library(tidyverse) # Loads up the packages
# Read in the csv of our penguin data
penguins <- read_csv('https://osf.io/qhkma/download')
head(penguins, 5)
?count
count(penguins, species)
# Work out some basic pieces of information #
# number of total observations
# number of observations for each species
# Earliest and latest time points (period of data collection)
# nrow gives the number of rows - this is a single number
total_obs <- nrow(penguins)
# count will give the observations within each species, as a `tibble` which is like a small spreadsheet
species_count <- count(penguins, species)
# We can find the minimum and maximum year using summarise and the min/max functions, again, as a `tibble`
time_period <- summairse(penguins, starting = min(year), ending = max(year))
# Work out some basic pieces of information #
# number of total observations
# number of observations for each species
# Earliest and latest time points (period of data collection)
# nrow gives the number of rows - this is a single number
total_obs <- nrow(penguins)
# count will give the observations within each species, as a `tibble` which is like a small spreadsheet
species_count <- count(penguins, species)
# We can find the minimum and maximum year using summarise and the min/max functions, again, as a `tibble`
time_period <- summarise(penguins, starting = min(year), ending = max(year))
print(total_obs)
print(species_count)
print(time_period)
```{r}
```{r}
# Work out some basic pieces of information #
# number of total observations
# number of observations for each species
# Earliest and latest time points (period of data collection)
# nrow gives the number of rows - this is a single number
total_obs <- nrow(penguins)
# count will give the observations within each species, as a `tibble` which is like a small spreadsheet
species_count <- count(penguins, species)
# We can find the minimum and maximum year using summarise and the min/max functions, again, as a `tibble`
time_period <- summarise(penguins, starting = min(year), ending = max(year))
# Have a look at these variables
print(total_obs)
print(species_count)
print(time_period)
# We're ready to start our first results section line!
```{r}
# Loads up the packages
library(tidyverse)
# Read in the csv of our penguin data
penguins <- read_csv('https://osf.io/qhkma/download')
head(penguins, 5)
# Work out some basic pieces of information #
# number of total observations
# number of observations for each species
# Earliest and latest time points (period of data collection)
# nrow gives the number of rows - this is a single number
total_obs <- nrow(penguins)
# count will give the observations within each species, as a `tibble` which is like a small spreadsheet
species_count <- count(penguins, species)
# We can find the minimum and maximum year using summarise and the min/max functions, again, as a `tibble`
time_period <- summarise(penguins, starting = min(year), ending = max(year))
# Have a look at these variables
print(total_obs)
print(species_count)
print(time_period)
# We're ready to start our first results section line!
View(penguins)
# Work out some basic pieces of information #
# number of total observations
# number of observations for each species
# number of male/female penguins
# Earliest and latest time points (period of data collection)
# nrow gives the number of rows - this is a single number
total_obs <- nrow(penguins)
# count will give the observations within each species, as a `tibble` which is like a small spreadsheet
species_count <- count(penguins, species)
# Same as above for sex
sex_count <- count(penguins, sex)
# We can find the minimum and maximum year using summarise and the min/max functions, again, as a `tibble`
time_period <- summarise(penguins, starting = min(year), ending = max(year))
# Have a look at these variables
print(total_obs)
print(species_count)
print(sex_count)
print(time_period)
# We're ready to start our first results section line!
# We're ready to start our first results section line!
sex_count
filter(sex_count, is.na(species))
filter(sex_count, is_null(species))
filter(sex_count, species == NA)
filter(sex_count, sex == NA)
filter(sex_count, sex == 'NA')
filter(sex_count, is_null(sex))
filter(sex_count, is.na(sex))
View(penguins)
# Now we want to describe a variable of interest, which is the body mass of the penguins. Its easy to work out the mean and SD of this
body_descriptives <- summarise(penguins, mean_mass = mean(body_mass_g), stddev_mass = sd(body_mass_g))
View(body_descriptives)
# Now we want to describe a variable of interest, which is the body mass of the penguins. Its easy to work out the mean and SD of this
body_descriptives <- summarise(penguins, mean_mass = mean(body_mass_g, na.rm=TRUE), stddev_mass = sd(body_mass_g, na.rm=TRUE))
View(body_descriptives)
aov(body_mass_g ~ sex * species, data=penguins)
analysis <- aov(body_mass_g ~ sex * species, data=penguins)
summary(analysis)
library(palmerpenguins)
penguins
peng <- penguins[!is.na(penguins$body_mass_g), ]
peng
write.csv(x=peng, file='penguins.csv')
write.csv(x=peng, file='penguins.csv', row.names=FALSE)
write.csv(x=dplyr::slice_sample(peng, prop=.75), file='penguins_data.csv', row.names=FALSE)
setwd("~/Desktop/UKRN Markdown Example")
# Loads up the packages
library(tidyverse)
# Loads up the packages
library(tidyverse)
# Read in the csv of our penguin data
penguins <- read_csv('penguins_data.csv')
head(penguins, 5)
# nrow gives the number of rows - this is a single number
total_obs <- nrow(penguins)
# count will give the observations within each species, as a `tibble` which is like a small spreadsheet
species_count <- count(penguins, species)
# Same as above for sex
sex_count <- count(penguins, sex)
# We can find the minimum and maximum year using summarise and the min/max functions, again, as a `tibble`
time_period <- summarise(penguins, starting = min(year), ending = max(year))
print(total_obs)
print(species_count)
print(sex_count)
print(time_period)
